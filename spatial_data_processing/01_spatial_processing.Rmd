---
title: "Spatial processing"
author: "Quentin D. Read"
date: "3/28/2021"
output: html_document
---

```{r setup, include=FALSE}
# Render notebook without evaluating any of the code.
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

# Description

This document contains the spatial processing pipeline which has inputs of publicly available vector and raster files in the form they were downloaded, and outputs of processed and transformed vector and raster files, and CSV files with summary values calculated from the spatial data. The majority of the code is in R but there are some code chunks containing shell commands as well as Python scripts for spatial processing.

**NOTE**: Please verify file paths point to the correct locations before running code in this notebook.

# Input files

Following is a list of the input files needed for this pipeline. The accompanying spreadsheet includes their location on the web and the date they were downloaded.

## Polygon files

- The Nature Conservancy global terrestrial ecoregions shapefile
- United States administrative boundaries shapefile
- United States county boundaries shapefile
- Global country boundaries shapefile

## Raster files

- National Land Cover Dataset 2016 for CONUS, Alaska, and Hawaii 
- Global pastureland raster
- Global crop dominance raster
- United States gridded population raster 2010

# Clip TNC ecoregion raster to USA extent

This R code chunk takes the Nature Conservancy ecoregions shapefile and the USA counties shapefile (used later) and intersects them. The result (TNC ecoregions for the United States) is written to a shapefile.

```{r}
# Read TNC and USA shapefiles
library(sf)
library(tidyverse)
tnc <- st_read(dsn = file.path(data_path, 'tnc_terr_ecoregions'), layer = 'tnc_terr_ecoregions')
usa <- st_read(dsn = file.path(data_path, 'cb_2014_us_county_500k'), layer = 'cb_2014_us_county_500k') %>%
  st_zm() %>% # Drop Z-dimension
  filter(!STATEFP %in% c("60", "66", "69", "72", "78")) %>% # Remove Puerto Rico and territories
  st_union() %>%
  st_transform(st_crs(tnc))

tnc_usa <- st_intersection(tnc, usa)

st_write(tnc_usa, dsn = file.path(spatial_output_path, 'tnc_usa.gpkg'), driver = 'GPKG')
```

# Project everything to equal-area projections

This code chunk containing bash shell commands first creates a virtual raster for the NLCD 2016 raster and extracts its projection information (Albers equal-area). Next it projects the TNC USA shapefile to that same Albers equal-area projection. The result is written to .shp and .gpkg. It also projects the global TNC shapefile, and a global country boundaries shapefile, to the Mollweide equal-area projection. Next it projects the global cropland and pastureland rasters to the Mollweide projection. 

```{bash}
data_path="~/data"
spatial_output_path="~/output/spatial_output"

gdalbuildvrt ${data_path}/NLCD_L48/nlcd2016landcover.vrt ${data_path}/NLCD_L48/NLCD_2016_Land_Cover_L48_20190424.img

cd /nfs/qread-data/raw_data/landuse/ecoregions

# Transform TNC ecoregions clipped to USA extent to Albers equal area.
tncusaproj=`gdalsrsinfo ${spatial_output_path}/tnc_usa.gpkg -o proj4 | xargs`
nlcdproj=`gdalsrsinfo ${data_path}/NLCD_L48/nlcd2016landcover.vrt -o proj4 | xargs`

ogr2ogr -f "GPKG" -t_srs "${nlcdproj}" -s_srs "${tncusaproj}" tnc_usa_aea.gpkg tnc_usa.gpkg

# Mollweide projection for global analysis that preserves area.
proj_moll="+proj=moll +lon_0=0 +datum=WGS84 +units=m +no_defs"

# Transform global TNC ecoregions to Mollweide
tncproj=`gdalsrsinfo tnc_terr_ecoregions.prj -o proj4 | xargs`

ogr2ogr -f "GPKG" -t_srs "${proj_moll}" -s_srs "${tncproj}" tnc_global_equalarea.gpkg tnc_terr_ecoregions.shp

# Transform global country boundaries to Mollweide
countryproj=`gdalsrsinfo ne_50m_admin_0_countries.prj -o proj4 | xargs`

ogr2ogr -f "GPKG" -t_srs "${proj_moll}" -s_srs "${countryproj}" countries_global_equalarea.gpkg ne_50m_admin_0_countries.shp

# Transform both the cropland and pastureland raster layers to the Mollweide projection.

cd /nfs/qread-data/raw_data/landuse/global_aglands

pastureproj=`gdalsrsinfo pasture.tif -o proj4 | xargs`
cropdproj=`gdalsrsinfo GFSAD1KCD.2010.001.2016348142525.tif -o proj4 | xargs`

gdalwarp -t_srs "${proj_moll}" -s_srs "${pastureproj}" -of "VRT" pasture.tif pasture_equalarea.vrt
gdalwarp -t_srs "${proj_moll}" -s_srs "${cropdproj}" -of "VRT" GFSAD1KCD.2010.001.2016348142525.tif cropdominance_equalarea.vrt
```

# Do QC on USA county shapefile and project to equal area

This R code chunk reads in the raw county boundaries shapefile, projects it to Albers equal area, and corrects the county codes so that they matches the county codes we have in our other datasets. In order to do that, we also need to do a spatial union of some counties so that the codes match. We load an external crosswalk table of which counties to dissolve (these are mainly independent cities in Virginia that are merged with the county surrounding them). Finally the result is written to a .gpkg.

```{r}
library(sf)
library(tidyverse)
tnc_p4s <- '+proj=aea +lat_1=29.5 +lat_2=45.5 +lat_0=23 +lon_0=-96 +x_0=0 +y_0=0 +ellps=WGS84 +units=m +no_defs'
county_map <- st_read(dsn = file.path(data_path, 'cb_2014_us_county_500k'), layer = 'cb_2014_us_county_500k') %>%
  filter(!STATEFP %in% c("60", "66", "69", "72", "78")) %>% # Remove Puerto Rico and other overseas dependencies
  mutate(fips = paste0(STATEFP, COUNTYFP)) %>%
  st_zm() %>% # Get rid of Z dimension
  st_transform(tnc_p4s) # Transform to equal area projection

# Summary of differences:
# Harmonization must be done on the map to dissolve independent cities in VA with less than 100K population with the surrounding county
# Kalawao County and Maui County also need to be dissolved on the map.
# code 55901 in data is for an aggregation of two counties in WI that no longer exists so can be ignored
# 46113 recoded to 46102, 02270 recoded to 02158
# The remaining inconsistencies are with Alaska, but they are all "legacy rows" that are NA in the data so can be ignored too.
# Also combine Aleutians east and west into one area since it is not separated in the production data.

fips_harmonization <- read_csv(file.path(fp_crosswalk, 'fips_harmonization.csv'), col_types = 'ccccc')

# For each row of fips_harmonization, dissolve those map polygons into a single one and rename it.
# first reshape the data frame 
fips_harmonization <- fips_harmonization %>% 
  pivot_longer(starts_with("FIPS_map"), values_to = 'FIPS_map') %>%
  select(-name, -name_data) %>%
  filter(!is.na(FIPS_map))

# Join map with harmonization, group by harmonized fips, and dissolve
county_harmonized <- county_map %>%
  left_join(fips_harmonization, by = c('fips' = 'FIPS_map')) %>%
  mutate(FIPS_data = if_else(is.na(FIPS_data), fips, FIPS_data)) %>%
  group_by(FIPS_data) %>%
  summarize %>%
  mutate(fips_state = substr(FIPS_data, 1, 2), fips_county = substr(FIPS_data, 3, 5)) %>%
  rename(fips = FIPS_data)

st_write(county_harmonized, file.path(spatial_output_path, 'USA_county_2014_aea.gpkg'), driver = 'GPKG')
```

# Intersect county and TNC ecoregion polygons

This R code chunk takes as input the county and TNC ecoregion polygons for the USA, both in Albers equal-area projection, and intersects them to create all county-ecoregion combination polygons.

```{r}
# Load county and TNC polygons
tncmap <- st_read(file.path(spatial_output_path, 'tnc_usa_aea.gpkg'))
county_aea <- st_read(file.path(spatial_output_path, 'USA_county_2014_aea.gpkg'))

# Intersect the two
county_tnc <- st_intersection(county_aea, st_make_valid(tncmap)) 
# This results in 4654 polygons combining the two

# Write result as geopackage
st_write(county_tnc, dsn = file.path(spatial_output_path, 'county_tnc_aea_intersect.gpkg'))
```

# Intersect country and global TNC ecoregion polygons

This R code chunk takes as input the global country boundary and global TNC ecoregion polygons, both in Mollweide equal-area projection, and intersects them to create all country-ecoregion combination polygons.

```{r}
# Load country boundary and TNC polygons
tncmap <- st_read(dsn = file.path(spatial_output_path, 'tnc_global_equalarea.gpkg')) # 814 regions
countrymap <- st_read(dsn = file.path(spatial_output_path, 'countries_global_equalarea.gpkg')) # 241 regions

# Intersect the two
country_tnc <- st_intersection(tncmap, countrymap) 
# This results in 1718 polygons combining the two

# Areas of the intersected regions
country_tnc$area <- st_area(country_tnc)

# Write result as geopackage
st_write(country_tnc, dsn = file.path(spatial_output_path, 'countries_tnc_intersect.gpkg'))
```


# Get population counts in the county-TNC intersected polygons

In this R code chunk, we aggregate the gridded USA population data product from CIESIN by the intersected polygons created above to get a population total for each combination of county and ecoregion.

```{r}
library(raster)
library(sf)
library(tidyverse)
library(exactextractr)

# Read shapefile and the three grids: L48, HI, and AK
county_tnc <- st_read(file.path(spatial_output_path, 'data/cfs_io_analysis/county_tnc_aea_intersect.gpkg'))
usgrid <- raster(file.path(data_path, 'population_grids', 'uspop10.tif'))
higrid <- raster(file.path(data_path, 'population_grids', 'hipop10.tif'))
akgrid <- raster(file.path(data_path, 'population_grids', 'akpop10.tif'))

# Return shapefile to longlat. Each of the three uspopgrids is in the same longlat projection.
county_tnc_longlat <- county_tnc %>% st_transform(st_crs(usgrid))

# Extract population totals by intersected polygon
county_tnc_pop <- exact_extract(usgrid, county_tnc_longlat, fun = 'sum')
hi_pop <- exact_extract(higrid, county_tnc_longlat, fun = 'sum')
ak_pop <- exact_extract(akgrid, county_tnc_longlat, fun = 'sum')

# Combine all three sections into one data frame. 
county_tnc_pop_all <- rowSums(cbind(county_tnc_pop, hi_pop, ak_pop))

county_tnc_df <- county_tnc %>% 
  mutate(pop = county_tnc_pop_all) %>%
  st_drop_geometry %>%
  dplyr::select(fips_state, fips_county, ECO_CODE, pop) %>%
  setNames(c('state_fips', 'county_fips', 'TNC', 'pop'))

write_csv(county_tnc_df, file.path(spatial_output_path, 'population_county_x_TNC_longform.csv'))
```

# Get NLCD pixel counts in the county-TNC intersected polygons

Similarly to population above, we aggregate the NLCD land cover raster product by the intersected polygons, counting the number of all pixels in each class in each intersected polygon. However, this required using a Python script and running the code on a remote computing cluster. The Python script, `tabulateraster.py`, is included in this archive but is also reproduced here for completeness:

```{python}
from rasterstats import zonal_stats
from sys import argv
import pandas as pd

script, vector_file, raster_file, output_file = argv

tabulated_geojson = zonal_stats(vector_file, raster_file, categorical = True, geojson_out = True)

output_properties = [x['properties'] for x in tabulated_geojson]
outputdf = pd.DataFrame(output_properties)

outputdf.to_csv(output_file)
```

The shell script that calls the Python script, `countpixels.sh`, is included in this archive as well, and is also reproduced here for completeness:

```{bash}
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --job-name=countpxls

# Arguments with the file name of the two inputs and the output (to be created) passed with --export flag of sbatch
python3 tabulateraster.py ${vector_file} ${raster_file} ${output_file} 
```

The following bash shell commands are run to submit the job to the Slurm compute cluster:

```{bash}
EXEC="countpixels.sh"
outdir="~/output/spatial_output"
usaraster="${data_path}/NLCD_L48/nlcd2016landcover.vrt"
cd ~/virtualland/jobscripts

sbatch -J nlcdcountytnc --export=vector_file=${spatial_output_path}/county_tnc_aea_intersect.gpkg,raster_file=${usaraster},output_file=${outdir}/NLCD_2016_countyTNC.csv ${EXEC}
```

## Counts for Alaska and Hawaii

The above count will return incorrect values for Alaska and Hawaii because the NLCD rasters for Alaska and Hawaii are in unique projections. In the following set of bash shell commands we create virtual rasters for the Alaska and Hawaii NLCD rasters, get their CRS information, project the county-ecoregion intersected polygons into the Alaska and Hawaii projections, then aggregate the Alaska and Hawaii rasters by the county-TNC intersection polygons in the appropriate projection.

```{bash}
# Build VRTs from Alaska and Hawaii rasters
cd ${data_path}/NLCD_AK
gdalbuildvrt nlcd2016landcover_ak.vrt NLCD_2016_Land_Cover_AK_20200724.img
cd ${data_path}/NLCD_HI
gdalbuildvrt nlcd2001landcover_hi.vrt hi_landcover_wimperv_9-30-08_se5.img

# Get Alaska and Hawaii CRS
gdalsrsinfo -o wkt ${data_path}/NLCD_HI/hi_landcover_wimperv_9-30-08_se5.img > ~/hawaii_crs.wkt
gdalsrsinfo -o wkt ${data_path}/NLCD_AK/NLCD_2016_Land_Cover_AK_20200724.img > ~/alaska_crs.wkt

# Project to AK
ogr2ogr -f "GPKG" -t_srs ~/alaska_crs.wkt ${spatial_output_path}/county_tnc_intersect_alaska_crs.gpkg ${spatial_output_path}/county_tnc_aea_intersect.gpkg

# Project to HI
ogr2ogr -f "GPKG" -t_srs ~/hawaii_crs.wkt ${spatial_output_path}/county_tnc_intersect_hawaii_crs.gpkg ${spatial_output_path}/county_tnc_aea_intersect.gpkg

akraster="${data_path}/NLCD_AK/nlcd2016landcover_ak.vrt"
hiraster="${data_path}/NLCD_HI/nlcd2001landcover_hi.vrt"
cd ~/virtualland/jobscripts

# Extract AK and HI NLCD2016 
sbatch -J akcountytnc --export=vector_file=${spatial_output_path}/county_tnc_intersect_alaska_crs.gpkg,raster_file=${akraster},output_file=${outdir}/AK_NLCD_2016_countyTNC.csv ${EXEC}

sbatch -J hicountytnc --export=vector_file=${spatial_output_path}/county_tnc_intersect_hawaii_crs.gpkg,raster_file=${hiraster},output_file=${outdir}/HI_NLCD_2001_countyTNC.csv ${EXEC}
```

# Combine CONUS, Alaska, and Hawaii NLCD counts and extract cropland and pastureland

The relevant land cover classes are cropland, pastureland, and water, if we want the proportion of land (non-water) area in each county-ecoregion intersection that is taken up by cropland and pastureland. In the following R code chunk, we combine the summarized NLCD pixel counts for CONUS, Alaska, and Hawaii, then sum all classes other than cropland, pastureland, and water to an "other" category.

```{r}
nlcd_county_tnc <- read_csv(file.path(spatial_output_path, 'NLCD_2016_countyTNC.csv'), col_types = "ncccccccnnccccccccccnnnnnnnnnnnnnnnnn")
nlcd_county_tnc_hi <- read_csv(file.path(spatial_output_path,'HI_NLCD_2001_countyTNC.csv'), col_types = "ncccccccnnccccccccccnnnnnnnnnnnnnn")
nlcd_county_tnc_ak <- read_csv(file.path(spatial_output_path,'AK_NLCD_2016_countyTNC.csv'), col_types = "ncccccccnnccccccccccnnnnnnnnnnnnnnnnnnnn")

# Fill in the Alaska and Hawaii rows: get rid of AK and HI from main df, retain only AK and HI from smaller ones,
# and then bind rows together.
nlcd_county_tnc <- nlcd_county_tnc %>% filter(!fips_state %in% c('02', '15'))
nlcd_county_tnc_hi <- nlcd_county_tnc_hi %>% filter(fips_state %in% c('15'))
nlcd_county_tnc_ak <- nlcd_county_tnc_ak %>% filter(fips_state %in% c('02'))

nlcd_county_tnc <- bind_rows(nlcd_county_tnc, nlcd_county_tnc_hi, nlcd_county_tnc_ak)

# Reshape to long
# Aggregate by cropland, pastureland, and other codes. Pasture 81, Crop 82, Water 11, Other Land = all others.
nlcd_county_tnc_long <- nlcd_county_tnc %>%
  rename(county = fips) %>%
  select(county, ECO_CODE, matches('^[0-9]{2}$')) %>%
  pivot_longer(-c(county, ECO_CODE), names_to = 'NLCD', values_to = 'n_pixels') %>%
  mutate(cover_class = case_when(NLCD == '81' ~ 'pasture',
                                 NLCD == '82' ~ 'crop',
                                 NLCD == '11' ~ 'water',
                                 TRUE ~ 'other'))

nlcd_county_tnc_ag <- nlcd_county_tnc_long %>%
  group_by(county, ECO_CODE, cover_class) %>%
  summarize(n_pixels = sum(n_pixels, na.rm = TRUE))

nlcd_county_tnc_ag_wide <- nlcd_county_tnc_ag %>%
  pivot_wider(id_cols = c(county, ECO_CODE), names_from = cover_class, values_from = n_pixels)

# Write intersected table to CSV
write_csv(nlcd_county_tnc_ag_wide, file.path(spatial_output_path, 'NLCDcrop_county_x_TNC.csv'))
```

# Get global crop and pasture pixel counts in the country-TNC intersected polygons

The pixel counts for the global crop dominance raster is done with the same Python script as above, executed by the following shell commands:

```{bash}
tnccountryvector="${spatial_output_path}/countries_tnc_intersect.gpkg"
rasterdir="${data_path}/global_cropland"

sbatch -J countcropd --export=vector_file=${tnccountryvector},\
	raster_file=${rasterdir}/cropdominance_equalarea.vrt,\
	output_file=${outdir}/global_count_cropdominance.csv ${EXEC}
```

Because the format of the pasture raster is different than the other rasters (continuous rather than categorical), a slightly modified Python script, `tabulateraster_pasture.py`, was used to get the pixel counts for the global pasture raster. It is included with this archive but also reproduced here for completeness:

```{python}
from rasterstats import zonal_stats
import pandas as pd

tabulated_geojson = zonal_stats("~/output/spatial_output/countries_tnc_intersect.gpkg", "~/data/global_cropland/pasture_equalarea.vrt", stats = "count min mean max median sum", nodata = float('-inf'), geojson_out = True)

output_properties = [x['properties'] for x in tabulated_geojson]
outputdf = pd.DataFrame(output_properties)

outputdf.to_csv("~/output/spatial_output/global_count_pasture.csv")
```

